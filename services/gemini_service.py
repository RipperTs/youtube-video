import requests
import json
import re
from datetime import datetime
from config.settings import Config

class GeminiService:
    """Gemini AIæœåŠ¡"""
    
    def __init__(self):
        self.api_key = Config.GEMINI_API_KEY
        self.base_url = Config.GEMINI_BASE_URL
        
    def analyze_video_with_logging(self, video_url, prompt=None, log_callback=None):
        """
        ä½¿ç”¨Geminiåˆ†æYouTubeè§†é¢‘ï¼ˆå¸¦æ—¥å¿—å›è°ƒï¼‰
        
        Args:
            video_url: YouTubeè§†é¢‘URL
            prompt: è‡ªå®šä¹‰åˆ†ææç¤ºè¯
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
        """
        if log_callback:
            yield log_callback("å¼€å§‹åˆ†æè§†é¢‘å†…å®¹...", "step")
            
        if not prompt:
            # è·å–å½“å‰æ—¥æœŸï¼Œç”¨äºæŠ¥å‘Šæ—¥æœŸ
            current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
            
            prompt = f"""
### **ã€MarketBeatæŠ•èµ„åˆ†ææŠ¥å‘Šç”Ÿæˆã€‘**

**# é‡è¦è¯´æ˜**
å½“å‰åˆ†ææ—¶é—´ï¼š{current_date}
è¯·åœ¨æŠ¥å‘Šå¼€å¤´çš„æ—¥æœŸä¸­ä½¿ç”¨ï¼š{current_date}
ä¸è¦æ¨æ–­æˆ–å‡è®¾è§†é¢‘çš„å‘å¸ƒæ—¶é—´ï¼Œç»Ÿä¸€ä½¿ç”¨å½“å‰åˆ†ææ—¶é—´ä½œä¸ºæŠ¥å‘Šæ—¥æœŸã€‚

**# è§’è‰²è®¾å®š**
ä½ æ˜¯ä¸€ååœ¨é¡¶çº§æŠ•èµ„é“¶è¡Œï¼ˆå¦‚é«˜ç››æˆ–æ‘©æ ¹å¤§é€šï¼‰å·¥ä½œçš„èµ„æ·±è¯åˆ¸åˆ†æå¸ˆã€‚ä½ æ“…é•¿ä»éç»“æ„åŒ–ä¿¡æ¯ï¼ˆå¦‚è´¢ç»è§†é¢‘ï¼‰ä¸­å¿«é€Ÿæå–æ ¸å¿ƒè§‚ç‚¹ï¼Œå¹¶ä»¥ä¸¥è°¨ã€å®¢è§‚ã€æ·±åº¦åˆ†æçš„é£æ ¼ï¼Œæ’°å†™æœºæ„çº§åˆ«çš„æŠ•èµ„ç ”ç©¶æŠ¥å‘Šã€‚

**# æ ¸å¿ƒä»»åŠ¡**
æˆ‘å°†æä¾›ä¸€ä¸ªYouTubeè§†é¢‘çš„é“¾æ¥ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. å…¨é¢å¤„ç†è¯¥è§†é¢‘çš„å†…å®¹ï¼ˆåŒ…æ‹¬å…¶æ ‡é¢˜ã€åˆ›ä½œè€…ä¿¡æ¯ä»¥åŠæ‰€æœ‰å£å¤´å’Œè§†è§‰ä¿¡æ¯ï¼‰ã€‚
2. åŸºäºè§†é¢‘å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½ç»¼åˆæ€§çš„ã€æ·±åº¦è¯¦å°½çš„æŠ•èµ„æ„è§æŠ¥å‘Šä¹¦ã€‚
3. æŠ¥å‘Šä¸ä»…æ˜¯å†…å®¹çš„æ€»ç»“ï¼Œæ›´è¦åŒ…å«ä½ ä½œä¸ºä¸“ä¸šåˆ†æå¸ˆçš„æ‰¹åˆ¤æ€§è¯„ä¼°ã€èƒŒæ™¯åˆ†æå’Œç­–ç•¥å»ºè®®ã€‚

**# è¾“å‡ºè¦æ±‚ï¼šæŠ¥å‘Šç»“æ„ä¸å†…å®¹æŒ‡å¼•**
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ä¸ƒä¸ªéƒ¨åˆ†ç»„ç»‡ä½ çš„æŠ¥å‘Šï¼Œä½¿ç”¨**Markdownæ ¼å¼**è¾“å‡ºï¼š

**æŠ¥å‘Šå¼€å¤´å¿…é¡»åŒ…å«ä»¥ä¸‹æ ¼å¼ï¼š**
```
# MarketBeatæŠ•èµ„åˆ†ææŠ¥å‘Šï¼š[è§†é¢‘ä¸»é¢˜]

**æŠ¥å‘Šæ—¥æœŸï¼š** {current_date}
**åˆ†æå¸ˆï¼š** [æ‚¨çš„å§“å]ï¼Œèµ„æ·±è¯åˆ¸åˆ†æå¸ˆ
```

## 1. æ‰§è¡Œæ‘˜è¦
- **æ ¸å¿ƒæŠ•èµ„è§‚ç‚¹:** ç”¨2-3å¥è¯é«˜åº¦æ¦‚æ‹¬è§†é¢‘æå‡ºçš„æ ¸å¿ƒæŠ•èµ„è®ºç‚¹æˆ–ç­–ç•¥
- **ä¸»è¦æŠ•èµ„å»ºè®®:** æ¸…æ™°åˆ—å‡ºè§†é¢‘æ¨èçš„æ ¸å¿ƒæŠ•èµ„æ ‡çš„ï¼ˆè‚¡ç¥¨ã€è¡Œä¸šç­‰ï¼‰å’Œæ“ä½œæ–¹å‘
- **é¢„æœŸæ”¶ç›Šä¸é£é™©ç­‰çº§:** æ€»ç»“è§†é¢‘ä¸­æåŠçš„æ½œåœ¨å›æŠ¥ç‡å’Œæ—¶é—´æ¡†æ¶ï¼Œå¹¶ç»™å‡ºç»¼åˆé£é™©è¯„çº§

## 2. ä¿¡æ¯æ¥æºåˆ†æ
- **è§†é¢‘åˆ›ä½œè€…èƒŒæ™¯ä¸å¯ä¿¡åº¦è¯„ä¼°:** å¯¹è§†é¢‘åˆ›ä½œè€…è¿›è¡ŒèƒŒæ™¯è¯„ä¼°ï¼Œåˆ†æå…¶è§‚ç‚¹å€¾å‘å’Œå¯ä¿¡åº¦
- **å†…å®¹æ—¶æ•ˆæ€§ä¸å¸‚åœºç¯å¢ƒ:** åŸºäºå½“å‰å¸‚åœºç¯å¢ƒ({current_date})åˆ†æè§†é¢‘è§‚ç‚¹çš„æ—¶æ•ˆæ€§
- **ä¿¡æ¯çš„å¯é æ€§åˆ†æ:** è¯„ä¼°æŠ¥å‘Šä¸­ä¸åŒæŠ•èµ„å»ºè®®çš„å¯é æ€§

## 3. æŠ•èµ„è§‚ç‚¹è§£æ
å¯¹è§†é¢‘ä¸­æåˆ°çš„**æ¯ä¸€ä¸ª**æŠ•èµ„æ ‡çš„æˆ–ä¸»é¢˜è¿›è¡Œæ·±å…¥åˆ†æï¼š
- **æŠ•èµ„é€»è¾‘å’Œç†ç”±:** è¯¦ç»†é˜è¿°è§†é¢‘ä½œè€…çœ‹å¥½è¯¥æ ‡çš„çš„æ ¸å¿ƒåŸå› 
- **åŸºæœ¬é¢/æŠ€æœ¯é¢åˆ†æè¦ç‚¹:** æå–è§†é¢‘ä¸­æåˆ°çš„ç›¸å…³æ•°æ®å’ŒæŠ€æœ¯ä¿¡å·
- **æ·±åº¦è§£è¯»ä¸æ‰¹åˆ¤æ€§è¯„ä¼°:** åŸºäºä¸“ä¸šçŸ¥è¯†ï¼Œå¯¹è§†é¢‘è§‚ç‚¹è¿›è¡Œå»¶ä¼¸è§£è¯»å’Œè¯„ä¼°
- **ç­–ç•¥åŒºåˆ†:** å°†å»ºè®®å½’ç±»ä¸ºä¸åŒçš„æŠ•èµ„ç­–ç•¥

## 4. å¸‚åœºç¯å¢ƒè¯„ä¼°
- **å®è§‚ç»æµç¯å¢ƒ:** åˆ†æå½“å‰å®è§‚ç»æµå› ç´ å¦‚ä½•æ”¯æŒæˆ–æŒ‘æˆ˜è§†é¢‘ä¸­çš„æŠ•èµ„è®ºç‚¹
- **ç›¸å…³è¡Œä¸š/æ¿å—è¶‹åŠ¿:** è®¨è®ºæ ‡çš„æ‰€å¤„è¡Œä¸šçš„æ•´ä½“è¶‹åŠ¿ã€ç«äº‰æ ¼å±€å’Œå‘å±•å‰æ™¯
- **æ”¿ç­–ç¯å¢ƒå½±å“:** åˆ†æç›¸å…³æ”¿ç­–å¯¹æŠ•èµ„æ ‡çš„çš„æ½œåœ¨å½±å“

## 5. é£é™©è¯„ä¼°
- **ä¸»è¦é£é™©å› ç´ è¯†åˆ«:** å…¨é¢è¯†åˆ«æ¯ä¸ªæŠ•èµ„å»ºè®®é¢ä¸´çš„æ ¸å¿ƒé£é™©
- **é£é™©ç­‰çº§è¯„å®š:** ä¸ºæ¯ä¸ªæŠ•èµ„ç»„åˆæˆ–æ ‡çš„æ˜ç¡®è¯„å®šé£é™©ç­‰çº§ï¼ˆä½/ä¸­/é«˜/æŠ•æœºçº§ï¼‰
- **æ½œåœ¨æŸå¤±é¢„ä¼°:** å¯¹é£é™©å‘ç”Ÿæ—¶çš„æ½œåœ¨è‚¡ä»·ä¸‹è¡Œç©ºé—´è¿›è¡Œåˆç†é¢„ä¼°

## 6. æŠ•èµ„å»ºè®®
- **å…·ä½“æ“ä½œå»ºè®®:** æä¾›å…·ä½“ã€å¯æ“ä½œçš„æŠ•èµ„æ‰§è¡Œå»ºè®®
- **ä»“ä½é…ç½®å»ºè®®:** æ ¹æ®é£é™©ç­‰çº§ï¼Œæå‡ºåˆç†çš„ä»“ä½ç®¡ç†å»ºè®®
- **æ­¢ç›ˆæ­¢æŸç­–ç•¥:** æå‡ºæ˜ç¡®çš„é€€å‡ºç­–ç•¥

## 7. è¡¥å……è¯´æ˜
- **éœ€è¦è¿›ä¸€æ­¥éªŒè¯çš„ä¿¡æ¯:** æŒ‡å‡ºæŠ•èµ„è€…åœ¨é‡‡çº³è¯¥ç­–ç•¥å‰éœ€è¦è‡ªè¡Œæ ¸å®çš„å…³é”®ä¿¡æ¯
- **å»ºè®®æŸ¥é˜…çš„é¢å¤–èµ„æ–™:** æ¨èæŠ•èµ„è€…å¯ä»¥æŸ¥é˜…çš„é¢å¤–ä¿¡æ¯æº
- **ä¸å…¶ä»–ä¸“ä¸šè§‚ç‚¹çš„å¯¹æ¯”:** ç®€è¦å¯¹æ¯”è§†é¢‘è§‚ç‚¹ä¸å¸‚åœºä¸»æµè§‚ç‚¹

**# åˆ†æå‡†åˆ™ä¸çº¦æŸ**
- **é£æ ¼ä¸è¯­è°ƒ:** ä½¿ç”¨ä¸“ä¸šã€ä¸¥è°¨ã€å®¢è§‚çš„é‡‘èåˆ†æè¯­è°ƒ
- **æ·±åº¦è¦æ±‚:** æŠ¥å‘Šå†…å®¹å¿…é¡»è¯¦å°½ï¼Œä¸å°‘äº3000ä¸­æ–‡å­—ç¬¦
- **è¯­è¨€:** ä½¿ç”¨**ä¸­æ–‡**è¿›è¡Œå›ç­”
- **æ ¼å¼:** ä¸¥æ ¼ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰æ ¼å¼
- **æ—¥æœŸæ ¼å¼:** æŠ¥å‘Šå¼€å¤´çš„æ—¥æœŸå¿…é¡»ä½¿ç”¨ï¼š{current_date}

**é‡è¦å£°æ˜ï¼š**
- æœ¬æŠ¥å‘ŠåŸºäºYouTubeè§†é¢‘å†…å®¹æ•´ç†ï¼Œä»…ä¾›å‚è€ƒ
- ä¸æ„æˆæ­£å¼æŠ•èµ„å»ºè®®ï¼ŒæŠ•èµ„éœ€è°¨æ…
- å»ºè®®ç»“åˆä¸“ä¸šæœºæ„ç ”æŠ¥è¿›è¡Œå†³ç­–

**è¯·å¼€å§‹åˆ†æè§†é¢‘å†…å®¹ã€‚**
            """
        
        if log_callback:
            yield log_callback("æ­£åœ¨è¿æ¥LLM API...", "info")
            
        url = f"{self.base_url}/models/gemini-2.5-pro:generateContent"
        
        headers = {
            'x-goog-api-key': self.api_key,
            'Content-Type': 'application/json'
        }
        
        payload = {
            'contents': [{
                'parts': [
                    {'text': prompt},
                    {
                        'file_data': {
                            'file_uri': video_url
                        }
                    }
                ]
            }]
        }
        
        try:
            if log_callback:
                yield log_callback("æ­£åœ¨å¤„ç†è§†é¢‘åˆ†æ...", "info")
                
            response = requests.post(url, headers=headers, json=payload)
            response.raise_for_status()
            
            if log_callback:
                yield log_callback("æ­£åœ¨è§£æåˆ†æç»“æœ...", "info")
            
            data = response.json()
            
            # æå–ç”Ÿæˆçš„å†…å®¹
            if 'candidates' in data and len(data['candidates']) > 0:
                content = data['candidates'][0]['content']['parts'][0]['text']
                if log_callback:
                    yield log_callback("è§†é¢‘åˆ†æå®Œæˆ", "success")
                
                # è¿”å›å®Œæ•´çš„åˆ†æç»“æœï¼ŒåŒæ—¶æä¾›åŸå§‹å†…å®¹å’Œç»“æ„åŒ–æ•°æ®
                analysis_result = {
                    'raw_content': content,
                    'summary': content  # ä¿æŒå…¼å®¹æ€§
                }
                
                # è§£æå‡ºç»“æ„åŒ–æ•°æ®ä»¥ä¾¿åç»­å¤„ç†
                try:
                    parsed_result = self._parse_analysis_result(content)
                    analysis_result.update(parsed_result)
                except Exception as e:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œè‡³å°‘ä¿è¯åŸºæœ¬å­—æ®µå­˜åœ¨
                    analysis_result.update({
                        'companies': [],
                        'market_events': [],
                        'investment_views': [],
                        'risks': []
                    })
                
                yield analysis_result
            else:
                if log_callback:
                    yield log_callback("Gemini APIè¿”å›äº†ç©ºçš„åˆ†æç»“æœ", "error")
                raise Exception("Gemini APIè¿”å›äº†ç©ºçš„åˆ†æç»“æœ")
                
        except requests.RequestException as e:
            if log_callback:
                yield log_callback(f"Gemini APIè¯·æ±‚å¤±è´¥: {str(e)}", "error")
            raise Exception(f"Geminiè§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
    
    def extract_stocks_from_video_with_logging(self, video_url, log_callback=None):
        """
        ä»è§†é¢‘ä¸­æå–è‚¡ç¥¨ä»£ç å’Œç›¸å…³ä¿¡æ¯ï¼ˆå¸¦æ—¥å¿—å›è°ƒï¼‰
        
        Args:
            video_url: YouTubeè§†é¢‘URL
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
        """
        if log_callback:
            yield log_callback("å¼€å§‹æå–è§†é¢‘ä¸­çš„è‚¡ç¥¨ä¿¡æ¯...", "step")
            
        prompt = """
        è¯·ä»”ç»†åˆ†æè¿™ä¸ªYouTubeè§†é¢‘ï¼Œä¸“é—¨æå–è§†é¢‘ä¸­æåˆ°çš„è‚¡ç¥¨ä¿¡æ¯ï¼š

        1. è¯†åˆ«æ‰€æœ‰æ˜ç¡®æåˆ°çš„è‚¡ç¥¨ä»£ç ï¼ˆå¦‚AAPLã€GOOGLã€TSLAç­‰ï¼‰
        2. è¯†åˆ«æåˆ°çš„å…¬å¸åç§°ï¼ˆå¦‚è‹¹æœã€è°·æ­Œã€ç‰¹æ–¯æ‹‰ç­‰ï¼‰
        3. è¯„ä¼°æ¯ä¸ªè‚¡ç¥¨/å…¬å¸åœ¨è§†é¢‘ä¸­çš„é‡è¦æ€§å’Œè®¨è®ºæ·±åº¦
        4. åˆ¤æ–­å¯¹æ¯ä¸ªè‚¡ç¥¨çš„è§‚ç‚¹å€¾å‘ï¼ˆç§¯æ/æ¶ˆæ/ä¸­æ€§ï¼‰

        è¯·ä»¥ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
        {
            "extracted_stocks": [
                {
                    "symbol": "AAPL",
                    "name": "Apple Inc.",
                    "confidence": "high/medium/low",
                    "sentiment": "positive/negative/neutral",
                    "discussion_points": ["è¦ç‚¹1", "è¦ç‚¹2"]
                }
            ],
            "summary": "è§†é¢‘ä¸­è‚¡ç¥¨è®¨è®ºçš„æ€»ä½“æ‘˜è¦"
        }

        å¦‚æœè§†é¢‘ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°å…·ä½“è‚¡ç¥¨ï¼Œè¯·è¿”å›ç©ºçš„extracted_stocksæ•°ç»„ã€‚
        """
        
        if log_callback:
            yield log_callback("æ­£åœ¨è¿æ¥Gemini APIè¿›è¡Œè‚¡ç¥¨æå–...", "info")
            
        url = f"{self.base_url}/models/gemini-2.5-pro:generateContent"
        
        headers = {
            'x-goog-api-key': self.api_key,
            'Content-Type': 'application/json'
        }
        
        payload = {
            'contents': [{
                'parts': [
                    {'text': prompt},
                    {
                        'file_data': {
                            'file_uri': video_url
                        }
                    }
                ]
            }]
        }
        
        try:
            if log_callback:
                yield log_callback("æ­£åœ¨å¤„ç†è‚¡ç¥¨æå–...", "info")
                
            response = requests.post(url, headers=headers, json=payload)
            response.raise_for_status()
            
            if log_callback:
                yield log_callback("æ­£åœ¨è§£ææå–ç»“æœ...", "info")
            
            data = response.json()
            
            # æå–ç”Ÿæˆçš„å†…å®¹
            if 'candidates' in data and len(data['candidates']) > 0:
                content = data['candidates'][0]['content']['parts'][0]['text']
                if log_callback:
                    yield log_callback("è‚¡ç¥¨æå–å®Œæˆ", "success")
                yield self._parse_stock_extraction_result(content)
            else:
                if log_callback:
                    yield log_callback("Gemini APIè¿”å›äº†ç©ºçš„è‚¡ç¥¨æå–ç»“æœ", "error")
                raise Exception("Gemini APIè¿”å›äº†ç©ºçš„è‚¡ç¥¨æå–ç»“æœ")
                
        except requests.RequestException as e:
            if log_callback:
                yield log_callback(f"è‚¡ç¥¨æå–å¤±è´¥: {str(e)}", "error")
            raise Exception(f"Geminiè‚¡ç¥¨æå–å¤±è´¥: {str(e)}")

    def analyze_video(self, video_url, prompt=None):
        """
        ä½¿ç”¨Geminiåˆ†æYouTubeè§†é¢‘ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        """
        # ä½¿ç”¨å¸¦æ—¥å¿—çš„æ–¹æ³•ï¼Œä½†ä¸æä¾›æ—¥å¿—å›è°ƒ
        results = list(self.analyze_video_with_logging(video_url, prompt))
        # è¿”å›æœ€åä¸€ä¸ªéå­—ç¬¦ä¸²ç»“æœï¼ˆåˆ†æç»“æœï¼‰
        for result in reversed(results):
            if not isinstance(result, str):
                return result
        return None
        
    def extract_stocks_from_video(self, video_url):
        """
        ä»è§†é¢‘ä¸­æå–è‚¡ç¥¨ä»£ç å’Œç›¸å…³ä¿¡æ¯ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        """
        # ä½¿ç”¨å¸¦æ—¥å¿—çš„æ–¹æ³•ï¼Œä½†ä¸æä¾›æ—¥å¿—å›è°ƒ
        results = list(self.extract_stocks_from_video_with_logging(video_url))
        # è¿”å›æœ€åä¸€ä¸ªéå­—ç¬¦ä¸²ç»“æœï¼ˆæå–ç»“æœï¼‰
        for result in reversed(results):
            if not isinstance(result, str):
                return result
        return None
    
    def _parse_stock_extraction_result(self, content):
        """è§£æè‚¡ç¥¨æå–ç»“æœ"""
        try:
            # å°è¯•è§£æJSONæ ¼å¼çš„å›å¤
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return result
        except:
            pass
        
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
        extracted_stocks = []
        lines = content.split('\n')
        
        for line in lines:
            # ç®€å•çš„è‚¡ç¥¨ä»£ç è¯†åˆ«
            stock_symbols = re.findall(r'\b[A-Z]{1,5}\b', line)
            for symbol in stock_symbols:
                if len(symbol) >= 2 and symbol in ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN', 'NVDA', 'META', 'NFLX', 'AMD', 'INTC']:
                    extracted_stocks.append({
                        'symbol': symbol,
                        'name': '',
                        'confidence': 'medium',
                        'sentiment': 'neutral',
                        'discussion_points': []
                    })
        
        return {
            'extracted_stocks': extracted_stocks,
            'summary': content[:200]
        }
    
    def _parse_analysis_result(self, content):
        """è§£æGeminiåˆ†æç»“æœ"""
        return {
            'raw_content': content,
            'summary': self._extract_summary(content),
            'companies': self._extract_companies(content),
            'market_events': self._extract_market_events(content),
            'investment_views': self._extract_investment_views(content),
            'risks': self._extract_risks(content)
        }
    
    def _extract_summary(self, content):
        """æå–è§†é¢‘å†…å®¹æ‘˜è¦"""
        # é¦–å…ˆå°è¯•æå–"æ‰§è¡Œæ‘˜è¦"éƒ¨åˆ†
        lines = content.split('\n')
        summary_text = ""
        
        # æŸ¥æ‰¾"æ‰§è¡Œæ‘˜è¦"æˆ–ç›¸å…³ç« èŠ‚
        summary_section_started = False
        next_section_started = False
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # æ£€æŸ¥æ˜¯å¦å¼€å§‹æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†
            if ('æ‰§è¡Œæ‘˜è¦' in line or '## 1.' in line or 'æ ¸å¿ƒæŠ•èµ„è§‚ç‚¹' in line or 
                'ä¸»è¦æŠ•èµ„å»ºè®®' in line or line.startswith('## 1')):
                summary_section_started = True
                continue
            
            # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ä¸‹ä¸€ä¸ªç« èŠ‚
            if summary_section_started and (line.startswith('## 2') or 
                                          'ä¿¡æ¯æ¥æºåˆ†æ' in line or 
                                          line.startswith('# 2') or
                                          ('##' in line and 'æ‰§è¡Œæ‘˜è¦' not in line and 'æŠ•èµ„è§‚ç‚¹' not in line)):
                next_section_started = True
                break
            
            # æ”¶é›†æ‘˜è¦å†…å®¹
            if summary_section_started and not next_section_started:
                if line.startswith('*') or line.startswith('-') or line.startswith('â€¢'):
                    summary_text += line + "\n"
                elif line and not line.startswith('#'):
                    summary_text += line + "\n"
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ‰§è¡Œæ‘˜è¦ï¼Œä½¿ç”¨å‰é¢çš„å†…å®¹
        if not summary_text:
            # æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„è¡Œä½œä¸ºæ‘˜è¦
            summary_lines = []
            for line in lines:
                if any(keyword in line for keyword in ['æŠ•èµ„', 'å»ºè®®', 'è§‚ç‚¹', 'åˆ†æ', 'è‚¡ç¥¨', 'å¸‚åœº']):
                    summary_lines.append(line.strip())
                if len(summary_lines) >= 5:  # é™åˆ¶é•¿åº¦
                    break
            
            if summary_lines:
                summary_text = '\n'.join(summary_lines)
            else:
                # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨å†…å®¹å‰200å­—ç¬¦
                summary_text = content[:300]
        
        return summary_text.strip() if summary_text else 'æš‚æ— æ‘˜è¦'
    
    def _extract_companies(self, content):
        """æå–æåˆ°çš„å…¬å¸"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…å¯ä»¥ç”¨å‘½åå®ä½“è¯†åˆ«
        companies = []
        common_stocks = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN', 'NVDA', 'META']
        for stock in common_stocks:
            if stock in content.upper():
                companies.append(stock)
        return companies
    
    def _extract_market_events(self, content):
        """æå–å¸‚åœºäº‹ä»¶"""
        events = []
        event_keywords = ['è´¢æŠ¥', 'ä¸šç»©', 'å‘å¸ƒ', 'æ”¶è´­', 'åˆå¹¶', 'æ–°äº§å“']
        lines = content.split('\n')
        for line in lines:
            if any(keyword in line for keyword in event_keywords):
                events.append(line.strip())
        return events[:5]
    
    def _extract_investment_views(self, content):
        """æå–æŠ•èµ„è§‚ç‚¹"""
        views = []
        view_keywords = ['å»ºè®®', 'é¢„æµ‹', 'ç›®æ ‡ä»·', 'è¯„çº§', 'çœ‹å¥½', 'çœ‹ç©º']
        lines = content.split('\n')
        for line in lines:
            if any(keyword in line for keyword in view_keywords):
                views.append(line.strip())
        return views[:3]
    

    def _parse_batch_analysis_result(self, content, videos):
        """è§£ææ‰¹é‡åˆ†æç»“æœ"""
        try:
            # å°è¯•è§£æJSONæ ¼å¼çš„å›å¤
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                # æ·»åŠ è§†é¢‘ä¿¡æ¯åˆ°ç»“æœä¸­
                if 'individual_analyses' in result:
                    for i, analysis in enumerate(result['individual_analyses']):
                        if i < len(videos):
                            analysis['video_info'] = videos[i]
                return result
        except:
            pass
        
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•
        return self._fallback_batch_analysis(content, videos)
    
    def _fallback_batch_analysis(self, content, videos):
        """å¤‡ç”¨çš„æ‰¹é‡åˆ†æè§£ææ–¹æ³•"""
        return {
            'batch_summary': {
                'total_videos': len(videos),
                'analysis_date': datetime.now().strftime('%Y-%m-%d'),
                'main_themes': ['æŠ•èµ„åˆ†æ', 'å¸‚åœºè§‚ç‚¹'],
                'overall_sentiment': 'ä¸­æ€§',
                'key_insights': [content[:200] + '...' if len(content) > 200 else content]
            },
            'individual_analyses': [
                {
                    'video_index': i + 1,
                    'video_info': video,
                    'core_message': f'è§†é¢‘{i+1}çš„æ ¸å¿ƒè§‚ç‚¹',
                    'investment_thesis': 'å¾…åˆ†æ',
                    'mentioned_companies': [],
                    'key_points': ['å†…å®¹åˆ†æä¸­'],
                    'sentiment': 'ä¸­æ€§',
                    'confidence_level': 'ä¸­'
                }
                for i, video in enumerate(videos)
            ],
            'consolidated_insights': {
                'common_themes': ['æŠ•èµ„ä¸»é¢˜'],
                'consensus_views': ['å¸‚åœºè§‚ç‚¹'],
                'divergent_opinions': [],
                'investment_opportunities': [],
                'risk_factors': []
            },
            'raw_content': content
        }
    
    def analyze_batch_videos(self, video_urls, log_callback=None):
        """
        æ‰¹é‡åˆ†æå¤šä¸ªYouTubeè§†é¢‘ï¼ˆæœ€å¤š10ä¸ªï¼‰
        
        Args:
            video_urls: YouTubeè§†é¢‘URLåˆ—è¡¨
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
        """
        if len(video_urls) > 10:
            raise ValueError("æ‰¹é‡åˆ†ææœ€å¤šæ”¯æŒ10ä¸ªè§†é¢‘")
        
        if log_callback:
            yield log_callback("å¼€å§‹æ‰¹é‡åˆ†æè§†é¢‘å†…å®¹...", "step")
            
        # æ ¹æ®è§†é¢‘æ•°é‡ç”ŸæˆåŠ¨æ€çš„è§†é¢‘åˆ†ææ ¼å¼
        video_analysis_format = ""
        for i in range(len(video_urls)):
            video_analysis_format += f"- **è§†é¢‘{i+1}**: æ ¸å¿ƒæŠ•èµ„è§‚ç‚¹å’Œå»ºè®®\n"
        
        # è·å–å½“å‰æ—¥æœŸï¼Œç”¨äºæŠ¥å‘Šæ—¥æœŸ
        current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        # é€‚é…æ‰¹é‡åˆ†æçš„æç¤ºè¯
        prompt = f"""
### **ã€æ‰¹é‡YouTubeè§†é¢‘æŠ•èµ„åˆ†ææŠ¥å‘Šã€‘**

**# é‡è¦è¯´æ˜**
å½“å‰åˆ†ææ—¶é—´ï¼š{current_date}
è¯·åœ¨æŠ¥å‘Šå¼€å¤´çš„æ—¥æœŸä¸­ä½¿ç”¨ï¼š{current_date}
ä¸è¦æ¨æ–­æˆ–å‡è®¾è§†é¢‘çš„å‘å¸ƒæ—¶é—´ï¼Œç»Ÿä¸€ä½¿ç”¨å½“å‰åˆ†ææ—¶é—´ä½œä¸ºæŠ¥å‘Šæ—¥æœŸã€‚

**# è§’è‰²è®¾å®š**
ä½ æ˜¯ä¸€åèµ„æ·±è¯åˆ¸åˆ†æå¸ˆï¼Œæ“…é•¿ä»å¤šä¸ªè´¢ç»è§†é¢‘ä¸­æå–æ ¸å¿ƒæŠ•èµ„è§‚ç‚¹ï¼Œå¹¶è¿›è¡Œç»¼åˆåˆ†æã€‚

**# æ ¸å¿ƒä»»åŠ¡**
æˆ‘å°†æä¾›{len(video_urls)}ä¸ªYouTubeè§†é¢‘ã€‚ä½ éœ€è¦ï¼š
1. åˆ†ææ¯ä¸ªè§†é¢‘çš„æŠ•èµ„å†…å®¹å’Œè§‚ç‚¹
2. è¯†åˆ«å…±åŒä¸»é¢˜å’Œä¸€è‡´æ€§è§‚ç‚¹
3. ç”Ÿæˆä¸€ä»½ç»¼åˆæ€§çš„æŠ•èµ„è§‚ç‚¹æŠ¥å‘Š

**# è¾“å‡ºè¦æ±‚**
è¯·ä½¿ç”¨**Markdownæ ¼å¼**ï¼ŒæŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºä¸€ä»½å®Œæ•´çš„æŠ•èµ„åˆ†ææŠ¥å‘Šï¼š

**æŠ¥å‘Šå¼€å¤´å¿…é¡»åŒ…å«ä»¥ä¸‹æ ¼å¼ï¼š**
```
# MarketBeatæ‰¹é‡æŠ•èµ„åˆ†ææŠ¥å‘Š

**æŠ¥å‘Šæ—¥æœŸï¼š** {current_date}
**åˆ†æå¸ˆï¼š** [æ‚¨çš„å§“å]ï¼Œèµ„æ·±è¯åˆ¸åˆ†æå¸ˆ
**åˆ†æè§†é¢‘æ•°é‡ï¼š** {len(video_urls)}ä¸ª
```

## ğŸ“Š æ‰¹é‡åˆ†ææ¦‚è§ˆ
- **è§†é¢‘æ•°é‡**: {len(video_urls)}ä¸ª
- **ä¸»è¦è®¨è®ºä¸»é¢˜**: è¯†åˆ«å‡ºçš„æ ¸å¿ƒæŠ•èµ„ä¸»é¢˜
- **æ•´ä½“æŠ•èµ„æƒ…ç»ª**: ç§¯æ/ä¸­æ€§/æ¶ˆæ

## ğŸ¯ å„è§†é¢‘æ ¸å¿ƒè§‚ç‚¹
å¯¹æ¯ä¸ªè§†é¢‘è¿›è¡Œç®€è¦åˆ†æï¼š
{video_analysis_format}

## ğŸ’¡ ç»¼åˆæŠ•èµ„æ´å¯Ÿ
- **å…±åŒè§‚ç‚¹**: å¤šä¸ªè§†é¢‘ä¸­çš„ä¸€è‡´æ€§è§‚ç‚¹
- **åˆ†æ­§è§‚ç‚¹**: ä¸åŒè§†é¢‘é—´çš„è§‚ç‚¹å·®å¼‚
- **æŠ•èµ„æœºä¼š**: ç»¼åˆè¯†åˆ«çš„æŠ•èµ„æœºä¼š

## ğŸ“ˆ ç»¼åˆæŠ•èµ„å»ºè®®
- **æ•´ä½“å»ºè®®**: åŸºäºå¤šè§†é¢‘åˆ†æçš„ç»¼åˆå»ºè®®
- **å…³æ³¨é‡ç‚¹**: éœ€è¦é‡ç‚¹å…³æ³¨çš„æŠ•èµ„æ ‡çš„æˆ–ä¸»é¢˜
- **é£é™©æç¤º**: ç»¼åˆé£é™©è¯„ä¼°

## ğŸš€ è¡ŒåŠ¨å»ºè®®
- **çŸ­æœŸå…³æ³¨**: è¿‘æœŸéœ€è¦å…³æ³¨çš„æŠ•èµ„åŠ¨å‘
- **ä¸­é•¿æœŸç­–ç•¥**: åŸºäºåˆ†æçš„ä¸­é•¿æœŸæŠ•èµ„æ€è·¯
- **è¿›ä¸€æ­¥ç ”ç©¶**: å»ºè®®æ·±å…¥ç ”ç©¶çš„æ–¹å‘

**# åˆ†æè¦æ±‚**
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- å†…å®¹è¯¦å°½ï¼Œä¸å°‘äº2000å­—
- ä¿æŒå®¢è§‚å’Œä¸“ä¸š
- é‡ç‚¹å…³æ³¨æŠ•èµ„é€»è¾‘å’Œè§‚ç‚¹
- è¯·æŒ‰ç…§ä¸Šè¿°æ ¼å¼å®Œæ•´è¾“å‡ºï¼Œä½ æœ‰èƒ½åŠ›è‡ªå·±åšå¥½æ’ç‰ˆ
- **æ—¥æœŸæ ¼å¼:** æŠ¥å‘Šå¼€å¤´çš„æ—¥æœŸå¿…é¡»ä½¿ç”¨ï¼š{current_date}

**è¯·å¼€å§‹åˆ†æè¿™{len(video_urls)}ä¸ªè§†é¢‘çš„å†…å®¹ã€‚**
        """
        
        if log_callback:
            yield log_callback("æ­£åœ¨è¿æ¥Gemini APIè¿›è¡Œæ‰¹é‡åˆ†æ...", "info")
            
        url = f"{self.base_url}/models/gemini-2.5-pro:generateContent"
        
        headers = {
            'x-goog-api-key': self.api_key,
            'Content-Type': 'application/json'
        }
        
        # æ„å»ºåŒ…å«å¤šä¸ªè§†é¢‘çš„è¯·æ±‚
        parts = []
        parts.append({'text': prompt})
        for i, video_url in enumerate(video_urls):
            parts.append({
                'file_data': {
                    'file_uri': video_url
                }
            })
        
        payload = {
            'contents': [{
                'parts': parts
            }]
        }

        print(payload)
        
        try:
            if log_callback:
                yield log_callback("æ­£åœ¨å¤„ç†æ‰¹é‡è§†é¢‘åˆ†æ...", "info")
                
            response = requests.post(url, headers=headers, json=payload)
            response.raise_for_status()
            
            if log_callback:
                yield log_callback("æ­£åœ¨è§£ææ‰¹é‡åˆ†æç»“æœ...", "info")
            
            data = response.json()
            
            # æå–ç”Ÿæˆçš„å†…å®¹
            if 'candidates' in data and len(data['candidates']) > 0:
                content = data['candidates'][0]['content']['parts'][0]['text']
                if log_callback:
                    yield log_callback("æ‰¹é‡è§†é¢‘åˆ†æå®Œæˆ", "success")
                
                # ç›´æ¥è¿”å›AIçš„åŸå§‹Markdownå†…å®¹
                yield {
                    'raw_content': content,
                    'summary': content,
                    'video_count': len(video_urls)
                }
            else:
                if log_callback:
                    yield log_callback("Gemini APIè¿”å›äº†ç©ºçš„æ‰¹é‡åˆ†æç»“æœ", "error")
                raise Exception("Gemini APIè¿”å›äº†ç©ºçš„æ‰¹é‡åˆ†æç»“æœ")
                
        except requests.RequestException as e:
            if log_callback:
                yield log_callback(f"æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}", "error")
            raise Exception(f"Geminiæ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
    
    def _extract_risks(self, content):
        """æå–é£é™©å› ç´ """
        risks = []
        risk_keywords = ['é£é™©', 'æŒ‘æˆ˜', 'ä¸ç¡®å®š', 'ä¸‹è·Œ', 'æ³¢åŠ¨']
        lines = content.split('\n')
        for line in lines:
            if any(keyword in line for keyword in risk_keywords):
                risks.append(line.strip())
        return risks[:3]
    
    def generate_text(self, prompt):
        """
        ä½¿ç”¨Geminiç”Ÿæˆæ–‡æœ¬å†…å®¹
        
        Args:
            prompt: æ–‡æœ¬ç”Ÿæˆæç¤ºè¯
            
        Returns:
            dict: åŒ…å«ç”Ÿæˆç»“æœçš„å­—å…¸
        """
        try:
            url = f"{self.base_url}/models/gemini-2.5-pro:generateContent"
            
            headers = {
                'Content-Type': 'application/json',
                'x-goog-api-key': self.api_key
            }
            
            data = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }],
                "generationConfig": {
                    "temperature": 0.7,
                    "topK": 32,
                    "topP": 1,
                    "maxOutputTokens": 8192,
                },
                "tools": [
                    {
                        "google_search": {}
                    }
                ]
            }
            
            print("ğŸ“¡ æ­£åœ¨è°ƒç”¨Gemini API (å¯ç”¨æœç´¢å·¥å…·)...")
            response = requests.post(url, headers=headers, json=data, timeout=180)  # å¢åŠ è¶…æ—¶æ—¶é—´ä»¥æ”¯æŒæœç´¢å·¥å…·
            
            if response.status_code == 200:
                result = response.json()
                
                if 'candidates' in result and len(result['candidates']) > 0:
                    candidate = result['candidates'][0]
                    content_parts = candidate['content']['parts']
                    
                    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æœç´¢å·¥å…·
                    used_search = False
                    if 'usageMetadata' in result and 'candidatesTokenCount' in result['usageMetadata']:
                        print(f"ğŸ” APIå“åº”åŒ…å« {len(content_parts)} ä¸ªéƒ¨åˆ†")
                    
                    # å¤„ç†å¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨çš„å“åº”
                    final_content = ""
                    for i, part in enumerate(content_parts):
                        if 'text' in part:
                            final_content += part['text']
                        elif 'functionCall' in part:
                            used_search = True
                            print(f"ğŸ” æ£€æµ‹åˆ°æœç´¢å·¥å…·è°ƒç”¨: {part.get('functionCall', {}).get('name', 'unknown')}")
                    
                    if used_search:
                        print("âœ… AIä½¿ç”¨äº†æœç´¢å·¥å…·è·å–å®æ—¶ä¿¡æ¯")
                    else:
                        print("â„¹ï¸ AIæœªä½¿ç”¨æœç´¢å·¥å…·")
                    
                    # å¦‚æœæ²¡æœ‰æ–‡æœ¬å†…å®¹ï¼Œå¯èƒ½æ˜¯å› ä¸ºåªæœ‰å·¥å…·è°ƒç”¨
                    if not final_content and content_parts:
                        final_content = "AIæ­£åœ¨ä½¿ç”¨æœç´¢å·¥å…·è·å–ä¿¡æ¯ï¼Œè¯·ç­‰å¾…å®Œæ•´å“åº”..."
                    
                    return {
                        'success': True,
                        'summary': final_content,
                        'raw_content': final_content,
                        'full_response': result  # ä¿ç•™å®Œæ•´å“åº”ç”¨äºè°ƒè¯•
                    }
                else:
                    return {
                        'success': False,
                        'error': 'æœªè·å–åˆ°æœ‰æ•ˆå›å¤',
                        'summary': 'ç”Ÿæˆå¤±è´¥'
                    }
            else:
                return {
                    'success': False,
                    'error': f'APIè¯·æ±‚å¤±è´¥: {response.status_code}',
                    'summary': 'ç”Ÿæˆå¤±è´¥'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'summary': 'ç”Ÿæˆå¤±è´¥'
            }